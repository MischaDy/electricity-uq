INFO:root:running main pipeline...
INFO:root:running preliminary checks/setup...
INFO:root:checking kwargs dict...
INFO:root:updating training flags...
INFO:root:loading data...
INFO:numexpr.utils:Note: detected 72 virtual cores but NumExpr set to maximum of 64, check "NUMEXPR_MAX_THREADS" environment variable.
INFO:numexpr.utils:Note: NumExpr detected 72 cores but "NUMEXPR_MAX_THREADS" not set, so enforcing safe limit of 16.
INFO:numexpr.utils:NumExpr defaulting to 16 threads.
/mnt/qb/work/ludwig/lqb589/my_code/helpers/misc_helpers.py:115: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  arr.drop(columns=ts_cols, inplace=True)
/mnt/qb/work/ludwig/lqb589/my_code/helpers/misc_helpers.py:115: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  arr.drop(columns=ts_cols, inplace=True)
/mnt/qb/work/ludwig/lqb589/my_code/helpers/misc_helpers.py:115: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  arr.drop(columns=ts_cols, inplace=True)
/mnt/qb/work/ludwig/lqb589/my_code/helpers/misc_helpers.py:115: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  arr.drop(columns=ts_cols, inplace=True)
INFO:root:data shapes: (35136, 8), (35040, 8), (35040, 8);  (35136, 1), (35040, 1), (35040, 1)
INFO:root:training base models...
INFO:root:training base_model_linreg...
INFO:root:training base_model_rf...
INFO:root:training base_model_nn...
INFO:root:saving base model results...
INFO:root:plotting base model results...
INFO:root:computing base model metrics...
INFO:root:running posthoc UQ methods...
INFO:root:No posthoc methods found and/or whitelisted. Skipping...
INFO:root:saving posthoc UQ results...
INFO:root:plotting posthoc results...
INFO:root:running native UQ methods...
INFO:root:running native methods...
INFO:root:running native_quantile_regression_nn...
INFO:root:training from scratch...
INFO:root:setup
INFO:root:setup model
INFO:root:setup meta-models
INFO:root:setup training
INFO:root:training...
INFO:root:epoch 1/100
INFO:root:epoch 2/100
INFO:root:epoch 3/100
INFO:root:epoch 4/100
INFO:root:epoch 5/100
INFO:root:epoch 6/100
INFO:root:epoch 7/100
INFO:root:epoch 8/100
INFO:root:epoch 9/100
INFO:root:epoch 10/100
INFO:root:epoch 11/100
INFO:root:epoch 12/100
INFO:root:epoch 13/100
INFO:root:epoch 14/100
INFO:root:epoch 15/100
INFO:root:epoch 16/100
INFO:root:epoch 17/100
INFO:root:epoch 18/100
INFO:root:epoch 19/100
INFO:root:epoch 20/100
INFO:root:epoch 21/100
INFO:root:epoch 22/100
INFO:root:epoch 23/100
INFO:root:epoch 24/100
INFO:root:epoch 25/100
INFO:root:epoch 26/100
INFO:root:epoch 27/100
INFO:root:epoch 28/100
INFO:root:epoch 29/100
INFO:root:epoch 30/100
INFO:root:epoch 31/100
INFO:root:epoch 32/100
INFO:root:epoch 33/100
INFO:root:epoch 34/100
INFO:root:epoch 35/100
INFO:root:epoch 36/100
INFO:root:epoch 37/100
INFO:root:epoch 38/100
INFO:root:epoch 39/100
INFO:root:epoch 40/100
INFO:root:epoch 41/100
INFO:root:epoch 42/100
INFO:root:epoch 43/100
INFO:root:epoch 44/100
INFO:root:epoch 45/100
INFO:root:epoch 46/100
INFO:root:epoch 47/100
INFO:root:epoch 48/100
INFO:root:epoch 49/100
INFO:root:epoch 50/100
INFO:root:epoch 51/100
INFO:root:epoch 52/100
INFO:root:epoch 53/100
INFO:root:epoch 54/100
INFO:root:epoch 55/100
INFO:root:epoch 56/100
INFO:root:epoch 57/100
INFO:root:epoch 58/100
INFO:root:epoch 59/100
INFO:root:epoch 60/100
INFO:root:epoch 61/100
INFO:root:epoch 62/100
INFO:root:epoch 63/100
INFO:root:epoch 64/100
INFO:root:epoch 65/100
INFO:root:epoch 66/100
INFO:root:epoch 67/100
INFO:root:epoch 68/100
INFO:root:epoch 69/100
INFO:root:epoch 70/100
INFO:root:epoch 71/100
INFO:root:epoch 72/100
INFO:root:epoch 73/100
INFO:root:epoch 74/100
INFO:root:epoch 75/100
INFO:root:epoch 76/100
INFO:root:epoch 77/100
INFO:root:epoch 78/100
INFO:root:epoch 79/100
INFO:root:epoch 80/100
INFO:root:epoch 81/100
INFO:root:epoch 82/100
INFO:root:epoch 83/100
INFO:root:epoch 84/100
INFO:root:epoch 85/100
INFO:root:epoch 86/100
INFO:root:epoch 87/100
INFO:root:epoch 88/100
INFO:root:epoch 89/100
INFO:root:epoch 90/100
INFO:root:epoch 91/100
INFO:root:epoch 92/100
INFO:root:epoch 93/100
INFO:root:epoch 94/100
INFO:root:epoch 95/100
INFO:root:epoch 96/100
INFO:root:epoch 97/100
INFO:root:epoch 98/100
INFO:root:epoch 99/100
INFO:root:epoch 100/100
INFO:root:done training.
INFO:root:filename train_qr_nn_losses had no extension. saving as PNG
INFO:root:saving model...
WARNING:root:5 quantiles are too few to compute a reliable std from (should be about 100)
INFO:root:running native_mvnn...
INFO:root:training from scratch...
INFO:root:running warmup...
  0%|          | 0/50 [00:00<?, ?it/s]  2%|▏         | 1/50 [00:04<03:36,  4.41s/it]  4%|▍         | 2/50 [00:07<03:05,  3.86s/it]  6%|▌         | 3/50 [00:11<02:56,  3.76s/it]  8%|▊         | 4/50 [00:15<02:48,  3.67s/it] 10%|█         | 5/50 [00:18<02:43,  3.63s/it] 12%|█▏        | 6/50 [00:22<02:43,  3.71s/it] 14%|█▍        | 7/50 [00:26<02:39,  3.72s/it] 16%|█▌        | 8/50 [00:29<02:36,  3.73s/it] 18%|█▊        | 9/50 [00:33<02:34,  3.78s/it] 20%|██        | 10/50 [00:37<02:30,  3.77s/it] 22%|██▏       | 11/50 [00:41<02:27,  3.77s/it] 24%|██▍       | 12/50 [00:45<02:23,  3.77s/it] 26%|██▌       | 13/50 [00:48<02:19,  3.77s/it] 28%|██▊       | 14/50 [00:52<02:15,  3.77s/it] 30%|███       | 15/50 [00:56<02:11,  3.75s/it] 32%|███▏      | 16/50 [00:59<02:04,  3.67s/it] 34%|███▍      | 17/50 [01:03<01:58,  3.60s/it] 36%|███▌      | 18/50 [01:07<01:56,  3.64s/it] 38%|███▊      | 19/50 [01:10<01:51,  3.59s/it] 40%|████      | 20/50 [01:14<01:46,  3.56s/it] 42%|████▏     | 21/50 [01:17<01:44,  3.60s/it] 44%|████▍     | 22/50 [01:21<01:40,  3.57s/it] 46%|████▌     | 23/50 [01:24<01:37,  3.61s/it] 48%|████▊     | 24/50 [01:28<01:36,  3.72s/it] 50%|█████     | 25/50 [01:32<01:33,  3.73s/it] 52%|█████▏    | 26/50 [01:36<01:29,  3.74s/it] 54%|█████▍    | 27/50 [01:40<01:27,  3.81s/it] 56%|█████▌    | 28/50 [01:44<01:23,  3.79s/it] 58%|█████▊    | 29/50 [01:47<01:19,  3.78s/it] 60%|██████    | 30/50 [01:51<01:15,  3.78s/it] 62%|██████▏   | 31/50 [01:55<01:10,  3.71s/it] 64%|██████▍   | 32/50 [01:58<01:06,  3.67s/it] 66%|██████▌   | 33/50 [02:02<01:01,  3.63s/it] 68%|██████▊   | 34/50 [02:05<00:57,  3.57s/it] 70%|███████   | 35/50 [02:09<00:52,  3.53s/it] 72%|███████▏  | 36/50 [02:12<00:50,  3.60s/it] 74%|███████▍  | 37/50 [02:16<00:46,  3.56s/it] 76%|███████▌  | 38/50 [02:19<00:42,  3.53s/it] 78%|███████▊  | 39/50 [02:23<00:39,  3.60s/it] 80%|████████  | 40/50 [02:27<00:36,  3.65s/it] 82%|████████▏ | 41/50 [02:31<00:33,  3.69s/it] 84%|████████▍ | 42/50 [02:35<00:30,  3.81s/it] 86%|████████▌ | 43/50 [02:39<00:26,  3.80s/it] 88%|████████▊ | 44/50 [02:42<00:22,  3.79s/it] 90%|█████████ | 45/50 [02:46<00:18,  3.78s/it] 92%|█████████▏| 46/50 [02:50<00:15,  3.78s/it] 94%|█████████▍| 47/50 [02:54<00:11,  3.74s/it] 96%|█████████▌| 48/50 [02:57<00:07,  3.67s/it] 98%|█████████▊| 49/50 [03:01<00:03,  3.62s/it]100%|██████████| 50/50 [03:04<00:00,  3.57s/it]100%|██████████| 50/50 [03:04<00:00,  3.69s/it]
WARNING:root:nn loss plot to be neither show nor saved. skipping entirely.
INFO:root:running main training run...
  0%|          | 0/100 [00:00<?, ?it/s]  1%|          | 1/100 [00:04<07:14,  4.39s/it]  2%|▏         | 2/100 [00:08<06:59,  4.28s/it]  3%|▎         | 3/100 [00:13<07:04,  4.37s/it]  4%|▍         | 4/100 [00:17<06:56,  4.34s/it]  5%|▌         | 5/100 [00:21<07:00,  4.43s/it]  6%|▌         | 6/100 [00:26<07:07,  4.55s/it]  7%|▋         | 7/100 [00:31<07:05,  4.57s/it]  8%|▊         | 8/100 [00:35<07:01,  4.58s/it]  9%|▉         | 9/100 [00:40<06:59,  4.62s/it] 10%|█         | 10/100 [00:45<06:54,  4.61s/it] 11%|█         | 11/100 [00:49<06:46,  4.56s/it] 12%|█▏        | 12/100 [00:53<06:33,  4.47s/it] 13%|█▎        | 13/100 [00:58<06:23,  4.41s/it] 14%|█▍        | 14/100 [01:02<06:14,  4.36s/it] 15%|█▌        | 15/100 [01:06<06:11,  4.37s/it] 16%|█▌        | 16/100 [01:11<06:04,  4.34s/it] 17%|█▋        | 17/100 [01:15<05:57,  4.31s/it] 18%|█▊        | 18/100 [01:20<06:04,  4.44s/it] 19%|█▉        | 19/100 [01:24<06:04,  4.49s/it] 20%|██        | 20/100 [01:29<06:02,  4.53s/it] 21%|██        | 21/100 [01:34<06:03,  4.61s/it] 22%|██▏       | 22/100 [01:38<05:59,  4.61s/it] 23%|██▎       | 23/100 [01:43<05:54,  4.61s/it] 24%|██▍       | 24/100 [01:47<05:50,  4.61s/it] 25%|██▌       | 25/100 [01:52<05:39,  4.53s/it] 26%|██▌       | 26/100 [01:56<05:29,  4.46s/it] 27%|██▋       | 27/100 [02:00<05:20,  4.39s/it] 28%|██▊       | 28/100 [02:05<05:13,  4.35s/it] 29%|██▉       | 29/100 [02:09<05:06,  4.31s/it] 30%|███       | 30/100 [02:13<05:02,  4.32s/it] 31%|███       | 31/100 [02:17<04:57,  4.31s/it] 32%|███▏      | 32/100 [02:22<04:58,  4.40s/it] 33%|███▎      | 33/100 [02:27<05:02,  4.51s/it] 34%|███▍      | 34/100 [02:31<04:59,  4.54s/it] 35%|███▌      | 35/100 [02:36<04:56,  4.56s/it] 36%|███▌      | 36/100 [02:41<05:01,  4.72s/it] 37%|███▋      | 37/100 [02:46<04:55,  4.68s/it] 38%|███▊      | 38/100 [02:50<04:44,  4.59s/it] 39%|███▉      | 39/100 [02:55<04:39,  4.59s/it] 40%|████      | 40/100 [02:59<04:29,  4.49s/it] 41%|████      | 41/100 [03:03<04:20,  4.42s/it] 42%|████▏     | 42/100 [03:08<04:14,  4.40s/it] 43%|████▎     | 43/100 [03:12<04:08,  4.36s/it] 44%|████▍     | 44/100 [03:16<04:02,  4.33s/it] 45%|████▌     | 45/100 [03:21<04:04,  4.45s/it] 46%|████▌     | 46/100 [03:25<04:02,  4.50s/it] 47%|████▋     | 47/100 [03:30<04:00,  4.53s/it] 48%|████▊     | 48/100 [03:35<04:00,  4.62s/it] 49%|████▉     | 49/100 [03:39<03:55,  4.61s/it] 50%|█████     | 50/100 [03:44<03:50,  4.61s/it] 51%|█████     | 51/100 [03:49<03:48,  4.67s/it] 52%|█████▏    | 52/100 [03:53<03:38,  4.56s/it] 53%|█████▎    | 53/100 [03:57<03:30,  4.49s/it] 54%|█████▍    | 54/100 [04:02<03:25,  4.46s/it] 55%|█████▌    | 55/100 [04:06<03:17,  4.39s/it] 56%|█████▌    | 56/100 [04:10<03:10,  4.34s/it] 57%|█████▋    | 57/100 [04:15<03:05,  4.32s/it] 58%|█████▊    | 58/100 [04:19<03:02,  4.35s/it] 59%|█████▉    | 59/100 [04:24<03:01,  4.43s/it] 60%|██████    | 60/100 [04:29<03:02,  4.57s/it] 61%|██████    | 61/100 [04:33<02:58,  4.59s/it] 62%|██████▏   | 62/100 [04:38<02:54,  4.59s/it] 63%|██████▎   | 63/100 [04:43<02:52,  4.65s/it] 64%|██████▍   | 64/100 [04:47<02:47,  4.64s/it] 65%|██████▌   | 65/100 [04:51<02:38,  4.54s/it] 66%|██████▌   | 66/100 [04:56<02:32,  4.49s/it] 67%|██████▋   | 67/100 [05:00<02:26,  4.43s/it] 68%|██████▊   | 68/100 [05:04<02:21,  4.41s/it] 69%|██████▉   | 69/100 [05:09<02:15,  4.36s/it] 70%|███████   | 70/100 [05:13<02:09,  4.32s/it] 71%|███████   | 71/100 [05:18<02:07,  4.40s/it] 72%|███████▏  | 72/100 [05:22<02:05,  4.47s/it] 73%|███████▎  | 73/100 [05:27<02:01,  4.51s/it] 74%|███████▍  | 74/100 [05:32<02:01,  4.66s/it] 75%|███████▌  | 75/100 [05:36<01:56,  4.65s/it] 76%|███████▌  | 76/100 [05:41<01:51,  4.63s/it] 77%|███████▋  | 77/100 [05:46<01:46,  4.65s/it] 78%|███████▊  | 78/100 [05:50<01:40,  4.57s/it] 79%|███████▉  | 79/100 [05:54<01:34,  4.48s/it] 80%|████████  | 80/100 [05:59<01:28,  4.42s/it] 81%|████████  | 81/100 [06:03<01:23,  4.37s/it] 82%|████████▏ | 82/100 [06:07<01:18,  4.36s/it] 83%|████████▎ | 83/100 [06:12<01:14,  4.38s/it] 84%|████████▍ | 84/100 [06:16<01:09,  4.33s/it] 85%|████████▌ | 85/100 [06:20<01:05,  4.40s/it] 86%|████████▌ | 86/100 [06:25<01:03,  4.52s/it] 87%|████████▋ | 87/100 [06:30<00:59,  4.54s/it] 88%|████████▊ | 88/100 [06:34<00:54,  4.56s/it] 89%|████████▉ | 89/100 [06:39<00:51,  4.66s/it] 90%|█████████ | 90/100 [06:44<00:46,  4.64s/it] 91%|█████████ | 91/100 [06:48<00:41,  4.61s/it] 92%|█████████▏| 92/100 [06:53<00:36,  4.58s/it] 93%|█████████▎| 93/100 [06:57<00:31,  4.48s/it] 94%|█████████▍| 94/100 [07:01<00:26,  4.41s/it] 95%|█████████▌| 95/100 [07:06<00:21,  4.37s/it] 96%|█████████▌| 96/100 [07:10<00:17,  4.33s/it] 97%|█████████▋| 97/100 [07:14<00:12,  4.30s/it] 98%|█████████▊| 98/100 [07:19<00:08,  4.30s/it] 99%|█████████▉| 99/100 [07:23<00:04,  4.40s/it]100%|██████████| 100/100 [07:28<00:00,  4.46s/it]100%|██████████| 100/100 [07:28<00:00,  4.49s/it]
INFO:root:filename train_mean_var_nn_losses had no extension. saving as PNG
INFO:root:saving model...
INFO:root:running native_gpytorch...
INFO:root:preparing data..
INFO:root:mapping data to device and making it contiguous...
INFO:root:training from scratch...
INFO:root:running function train_gpytorch (with timing)...
INFO:root:Planning to run on 2 GPUs.
INFO:root:epoch 1/100
Traceback (most recent call last):
  File "/mnt/qb/work/ludwig/lqb589/my_code/uq_comparison_pipeline.py", line 742, in <module>
    main()
  File "/mnt/qb/work/ludwig/lqb589/my_code/uq_comparison_pipeline.py", line 728, in main
    uq_comparer.compare_methods(
  File "/mnt/qb/work/ludwig/lqb589/my_code/uq_comparison_pipeline_abc.py", line 193, in compare_methods
    native_results = self.run_native_methods(
                     ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/qb/work/ludwig/lqb589/my_code/uq_comparison_pipeline_abc.py", line 467, in run_native_methods
    y_pred, y_quantiles, y_std = native_method(
                                 ^^^^^^^^^^^^^^
  File "/mnt/qb/work/ludwig/lqb589/my_code/uq_comparison_pipeline.py", line 610, in native_gpytorch
    model, likelihood = train_gpytorch(
                        ^^^^^^^^^^^^^^^
  File "/mnt/qb/work/ludwig/lqb589/my_code/helpers/misc_helpers.py", line 424, in wrapper
    result = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/mnt/qb/work/ludwig/lqb589/my_code/src_uq_methods_native/gp_regression_gpytorch.py", line 75, in train_gpytorch
    loss = -mll(y_pred, y_train).sum()
            ^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/gpytorch/module.py", line 31, in __call__
    outputs = self.forward(*inputs, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/gpytorch/mlls/exact_marginal_log_likelihood.py", line 82, in forward
    res = output.log_prob(target)
          ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/gpytorch/distributions/multivariate_normal.py", line 193, in log_prob
    inv_quad, logdet = covar.inv_quad_logdet(inv_quad_rhs=diff.unsqueeze(-1), logdet=True)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/operators/_linear_operator.py", line 1772, in inv_quad_logdet
    inv_quad_term, pinvk_logdet = func(
                                  ^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/functions/_inv_quad_logdet.py", line 132, in forward
    solves, t_mat = linear_op._solve(rhs, preconditioner, num_tridiag=num_random_probes)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/operators/_linear_operator.py", line 795, in _solve
    return utils.linear_cg(
           ^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/utils/linear_cg.py", line 186, in linear_cg
    residual = rhs - matmul_closure(initial_guess)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/operators/added_diag_linear_operator.py", line 77, in _matmul
    return torch.addcmul(self._linear_op._matmul(rhs), self._diag_tensor._diag.unsqueeze(-1), rhs)
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/operators/constant_mul_linear_operator.py", line 114, in _matmul
    res = self.base_linear_op._matmul(rhs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/operators/kernel_linear_operator.py", line 374, in _matmul
    return self.covar_mat @ rhs.contiguous()
           ^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/utils/memoize.py", line 59, in g
    return _add_to_cache(self, cache_name, method(self, *args, **kwargs), *args, kwargs_pkl=kwargs_pkl)
                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/linear_operator/operators/kernel_linear_operator.py", line 252, in covar_mat
    return self.covar_func(self.x1, self.x2, **self.tensor_params, **self.nontensor_params)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/gpytorch/kernels/keops/rbf_kernel.py", line 12, in _covar_func
    K = (-((x1_ - x2_) ** 2).sum(-1) / 2).exp()
            ~~~~^~~~~
  File "/home/ludwig/lqb589/.conda/envs/masterarbeit/lib/python3.12/site-packages/torch/utils/_device.py", line 106, in __torch_function__
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 36.79 GiB. GPU 0 has a total capacity of 10.75 GiB of which 10.49 GiB is free. Including non-PyTorch memory, this process has 270.00 MiB memory in use. Of the allocated memory 37.66 MiB is allocated by PyTorch, and 4.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
