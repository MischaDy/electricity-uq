{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcb878ef-930c-4472-accc-e5763cecc5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import helpers\n",
    "\n",
    "# importlib.reload(helpers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282754b3-465e-486f-83d2-19f82a153107",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "# import numpy.typing as npt\n",
    "\n",
    "import pandas as pd\n",
    "from mapie.subsample import BlockBootstrap\n",
    "from pmdarima.metrics import smape\n",
    "\n",
    "from scipy.stats import randint, norm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from uncertainty_toolbox.metrics_scoring_rule import nll_gaussian\n",
    "# from properscoring import crps_ensemble\n",
    "\n",
    "# from compare_methods import UQ_Comparer\n",
    "from helpers import get_data, IO_Helper\n",
    "\n",
    "from conformal_prediction import (train_base_model as train_base_model_cp, estimate_pred_interals_no_pfit_enbpi)\n",
    "from quantile_regression import estimate_quantiles as estimate_quantiles_qr\n",
    "\n",
    "import torch\n",
    "\n",
    "from laplace import Laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95790e-eff4-4637-baee-d29df012fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UQ COMPARER\n",
    "\n",
    "import copy\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from helpers import starfilter, is_ascending\n",
    "\n",
    "\n",
    "# todo: add type hints\n",
    "# noinspection PyPep8Naming\n",
    "class UQ_Comparer(ABC):\n",
    "    # todo: After these required inputs, they may accept any args or kwargs you wish.\n",
    "    \"\"\"\n",
    "    Usage:\n",
    "    1. Inherit from this class.\n",
    "    2. Override get_data, compute_metrics, and train_base_model.\n",
    "    3. Define all desired posthoc and native UQ methods. The required signature is:\n",
    "            (X_train, y_train, X_test, quantiles) -> (y_pred, y_quantiles, y_std)\n",
    "       Posthoc methods receive an additional base_model parameter, so their signature looks like:\n",
    "            (..., quantiles, base_model, *args, **kwargs) -> (y_pred, ...)\n",
    "       All posthoc and native UQ method names should start with 'posthoc_' and 'native_', respectively. They should\n",
    "       all be instance methods, not class or static methods.\n",
    "    4. Call compare_methods from the child class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, method_whitelist=None):\n",
    "        # todo: store train and test data once loaded\n",
    "        self.method_whitelist = method_whitelist\n",
    "\n",
    "    def compare_methods(self, quantiles, should_plot_data=True, should_plot_results=True, should_save_plots=True, plots_path=\".\", return_results=False, skip_deepcopy=False, base_model_params=None, output_uq_on_train=True) -> tuple[dict, dict] | dict[str, dict[str, dict[str, Any]]]:\n",
    "        # todo: improve, e.g. tuple[dict[str, tuple[np.array, np.array]], dict[str, tuple[np.array, np.array]]]\n",
    "        \"\"\"\n",
    "        :param base_model_params:\n",
    "        :param skip_deepcopy:\n",
    "        :param plots_path:\n",
    "        :param should_save_plots:\n",
    "        :param quantiles:\n",
    "        :param should_plot_data:\n",
    "        :param should_plot_results:\n",
    "        :param return_results: return native and posthoc results in addition to the native and posthoc metrics?\n",
    "        :param output_uq_on_train: whether to produce results for X_train, too. Output for X_test is always produced.\n",
    "        :return: UQ metrics and UQ results if return_results is False, else UQ metrics also native and posthoc results\n",
    "        \"\"\"\n",
    "        print(\"loading data\")\n",
    "        X_train, X_test, y_train, y_test, X, y = self.get_data()\n",
    "        print(\"data shapes:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "        if should_plot_data:\n",
    "            print(\"plotting data\")\n",
    "            plot_data(X_train, X_test, y_train, y_test, save_plot=should_save_plots, plots_path=plots_path)\n",
    "\n",
    "        print(\"running UQ methods\")\n",
    "        X_uq = np.row_stack((X_train, X_test)) if output_uq_on_train else X_test\n",
    "        uq_results = self.run_all_methods(X_train, y_train, X_uq, quantiles=quantiles, skip_deepcopy=skip_deepcopy, base_model_params=base_model_params)\n",
    "\n",
    "        if should_plot_results:\n",
    "            print(\"plotting native vs posthoc results\")\n",
    "            plot_uq_results_all(X_train, y_train, X_test, y, uq_results, quantiles, output_uq_on_train, save_plots=should_save_plots, plots_path=plots_path)\n",
    "\n",
    "        y_uq = y if output_uq_on_train else y_test\n",
    "        print(\"computing and comparing metrics\")\n",
    "        uq_metrics = {\n",
    "            uq_type: self.compute_all_metrics(methods_results, y_uq, quantiles=quantiles)\n",
    "            for uq_type, methods_results in uq_results.items()\n",
    "        }\n",
    "        if return_results:\n",
    "            return uq_metrics, uq_results\n",
    "        return uq_metrics\n",
    "\n",
    "    # todo: make classmethod?\n",
    "    @abstractmethod\n",
    "    def get_data(self) -> tuple[\n",
    "        npt.NDArray[float], npt.NDArray[float], npt.NDArray[float], npt.NDArray[float], npt.NDArray[float], npt.NDArray[float], ]:\n",
    "        \"\"\"\n",
    "\n",
    "        :return: X_train, X_test, y_train, y_test, X, y\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # todo: make classmethod?\n",
    "    @abstractmethod\n",
    "    def compute_metrics(self, y_pred, y_quantiles: Optional[npt.NDArray], y_std: Optional[npt.NDArray], y_true, quantiles):\n",
    "        \"\"\"\n",
    "        Evaluate a UQ method by compute all desired metrics.\n",
    "\n",
    "        :param y_pred:\n",
    "        :param y_quantiles: array of shape (n_samples, n_quantiles) containing the predicted quantiles of y_true\n",
    "        :param y_std: 1D array-like of predicted standard deviations around y_true\n",
    "        :param y_true:\n",
    "        :param quantiles: list of quantiles with which test to measure performance. They are expected to be symmetric\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # todo: make classmethod?\n",
    "    def compute_all_metrics(self, uq_results: dict[\n",
    "            str, tuple[\n",
    "                npt.NDArray[float], Optional[npt.NDArray[float]], Optional[npt.NDArray[float]], ], ], y_true, quantiles=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param quantiles: quantiles\n",
    "        :param uq_results: dict of (method_name, (y_pred, y_quantiles, y_std))\n",
    "        :param y_true:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return {\n",
    "            method_name: self.compute_metrics(y_pred, y_quantiles, y_std, y_true, quantiles=quantiles\n",
    "            )\n",
    "            for method_name, (y_pred, y_quantiles, y_std) in uq_results.items()\n",
    "        }\n",
    "\n",
    "    @abstractmethod\n",
    "    def train_base_model(self, X_train, y_train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def get_posthoc_methods(cls):\n",
    "        return cls._get_uq_methods_by_type(\"posthoc\")\n",
    "\n",
    "    @classmethod\n",
    "    def get_native_methods(cls):\n",
    "        return cls._get_uq_methods_by_type(\"native\")\n",
    "\n",
    "    def _get_uq_methods_by_type(self, uq_type: str):\n",
    "        \"\"\"\n",
    "\n",
    "        :param uq_type: one of \"native\", \"posthoc\"\n",
    "        :return: all instance methods (i.e. callable attributes) with prefix given by uq_type\n",
    "        \"\"\"\n",
    "        for attr_name in self.__class__.__dict__.keys():\n",
    "            attr = getattr(self, attr_name)\n",
    "            if attr_name.startswith(uq_type) and callable(attr):\n",
    "                yield attr_name, attr\n",
    "\n",
    "    def run_all_methods(self, X_train, y_train, X_uq, quantiles, skip_deepcopy=False, base_model_params=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X_train:\n",
    "        :param y_train:\n",
    "        :param X_uq:\n",
    "        :param quantiles:\n",
    "        :param skip_deepcopy:\n",
    "        :param base_model_params:\n",
    "        :return: dict of results: {'posthoc': posthoc_results, 'native': native_results\\\n",
    "        \"\"\"\n",
    "        uq_results = {}\n",
    "        for uq_type in [\"posthoc\", \"native\"]:\n",
    "            uq_result = self._run_methods(X_train, y_train, X_uq, quantiles=quantiles, uq_type=uq_type, skip_deepcopy=skip_deepcopy, base_model_params=base_model_params)\n",
    "            uq_results[uq_type] = uq_result\n",
    "        return uq_results\n",
    "\n",
    "    def _run_methods(self, X_train, y_train, X_uq, quantiles, *, uq_type, skip_deepcopy=False, base_model_params: dict = None, output_uq_on_train=True) -> dict[str, tuple[npt.NDArray[float], npt.NDArray[float], npt.NDArray[float]]]:\n",
    "        \"\"\"\n",
    "\n",
    "        :param base_model_params:\n",
    "        :param skip_deepcopy: whether to skip making a deepcopy of the base model. speed up execution, but can lead to\n",
    "         bugs if posthoc method affects the base model object. ignored for native methods\n",
    "        :param X_train:\n",
    "        :param y_train:\n",
    "        :param X_uq:\n",
    "        :param uq_type: one of: \"posthoc\", \"native\"\n",
    "        :return: dict of (method_name, (y_pred, y_quantiles)), where y_pred and y_quantiles are 1D and 2D, respectively\n",
    "        \"\"\"\n",
    "        assert uq_type in [\"posthoc\", \"native\"]\n",
    "        is_posthoc = uq_type == \"posthoc\"\n",
    "        if is_posthoc:\n",
    "            print(\"training base model\")\n",
    "            if base_model_params is None:\n",
    "                base_model_params = {}\n",
    "            base_model = self.train_base_model(X_train, y_train, **base_model_params)\n",
    "        print(f\"running {uq_type} methods\")\n",
    "        uq_methods = self._get_uq_methods_by_type(uq_type)\n",
    "        if self.method_whitelist is not None:\n",
    "            uq_methods = starfilter(lambda name, _: name in self.method_whitelist, uq_methods\n",
    "            )\n",
    "\n",
    "        uq_results = {}\n",
    "        for method_name, method in uq_methods:\n",
    "            if is_posthoc:\n",
    "                # noinspection PyUnboundLocalVariable\n",
    "                base_model_copy = (copy.deepcopy(base_model) if not skip_deepcopy else base_model\n",
    "                )\n",
    "                y_pred, y_quantiles, y_std = method(X_train, y_train, X_uq, quantiles, base_model_copy\n",
    "                )\n",
    "            else:\n",
    "                y_pred, y_quantiles, y_std = method(X_train, y_train, X_uq, quantiles)\n",
    "            uq_results[method_name] = y_pred, y_quantiles, y_std\n",
    "        return uq_results\n",
    "\n",
    "    @staticmethod\n",
    "    def stds_from_quantiles(quantiles: npt.NDArray):\n",
    "        \"\"\"\n",
    "        :param quantiles: array of shape (number of datapoints, number of quantiles), where number of quantiles should\n",
    "        be at least about 100\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        num_quantiles = quantiles.shape[1]\n",
    "        if num_quantiles < 50:\n",
    "            print(f\"warning: {num_quantiles} quantiles are too few to compute a reliable std from (should be about 100)\"\n",
    "            )\n",
    "        return np.std(quantiles, ddof=1, axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def pis_from_quantiles(quantiles):\n",
    "        mid = len(quantiles) // 2\n",
    "        first, second = quantiles[:mid], quantiles[mid:]\n",
    "        pi_limits = zip(first, reversed(second))\n",
    "        pis = [high - low for low, high in pi_limits]\n",
    "        return sorted(pis)\n",
    "\n",
    "    @staticmethod\n",
    "    def quantiles_from_pis(pis: npt.NDArray, check_order=False):\n",
    "        \"\"\"\n",
    "        currently \"buggy\" for odd number of quantiles.\n",
    "        :param check_order:\n",
    "        :param pis: prediction intervals array of shape (n_samples, 2, n_intervals)\n",
    "        :return: array of quantiles of shape (n_samples, 2 * n_intervals)\n",
    "        \"\"\"\n",
    "        # todo: assumption that quantile ordering is definitely consistant fulfilled?\n",
    "        if check_order:\n",
    "            assert np.all([is_ascending(pi[0, :], reversed(pi[1, :])) for pi in pis])\n",
    "        y_quantiles = np.array([sorted(pi.flatten()) for pi in pis])\n",
    "        return y_quantiles\n",
    "\n",
    "    @staticmethod\n",
    "    def optional(func):\n",
    "        # todo\n",
    "        \"\"\"\n",
    "        :param func:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        def optional_func(*args, **kwargs):\n",
    "            # todo: needed?\n",
    "            pass\n",
    "\n",
    "\n",
    "# PLOTTING\n",
    "\n",
    "\n",
    "def plot_data(X_train, X_test, y_train, y_test, figsize=(16, 5), ylabel=\"energy data\",  # todo: details!\n",
    "    save_plot=True, filename=\"data.png\", plots_path=\".\"):\n",
    "    \"\"\"visualize training and test sets\"\"\"\n",
    "    num_train_steps = X_train.shape[0]\n",
    "    num_test_steps = X_test.shape[0]\n",
    "\n",
    "    x_plot_train = np.arange(num_train_steps)\n",
    "    x_plot_test = x_plot_train + num_test_steps\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(x_plot_train, y_train)\n",
    "    plt.plot(x_plot_test, y_test)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend([\"Training data\", \"Test data\"])\n",
    "    if save_plot:\n",
    "        filepath = os.path.join(plots_path, filename)\n",
    "        plt.savefig(filepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_uq_results_all(X_train, y_train, X_test, y, uq_results, quantiles, output_uq_on_train: bool, save_plots=True, plots_path=\".\"):\n",
    "    os.makedirs(plots_path, exist_ok=True)\n",
    "    for res_type, results in uq_results.items():\n",
    "        if results:\n",
    "            print(f\"plotting {res_type} results...\")\n",
    "        else:\n",
    "            continue\n",
    "        # todo: allow results to have multiple PIs (corresp. to multiple alphas)?\n",
    "        for method_name, (y_preds, y_quantiles, y_std) in results.items():\n",
    "            if y_quantiles is None and y_std is None:\n",
    "                print(f\"warning: cannot plot method {method_name}, because both y_quantiles and y_std are None\"\n",
    "                )\n",
    "                continue\n",
    "            uq_type, *method_name_parts = method_name.split(\"_\")\n",
    "            plot_uq_result(X_train, X_test, y_train, y, y_preds, y_quantiles, y_std, quantiles, output_uq_on_train, plot_name=\" \".join(method_name_parts), uq_type=uq_type, save_plot=save_plots, plots_path=plots_path)\n",
    "\n",
    "\n",
    "def plot_uq_result(X_train, X_test, y_train, y, y_preds, y_quantiles, y_std, quantiles, output_uq_on_train, plot_name, uq_type, save_plot=True, plots_path=\".\"):\n",
    "    num_train_steps, num_test_steps = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    x_plot_train = np.arange(num_train_steps)\n",
    "    x_plot_full = np.arange(num_train_steps + num_test_steps)\n",
    "    x_plot_test = x_plot_train + num_test_steps  # shifting\n",
    "    x_plot_uq = x_plot_full if output_uq_on_train else x_plot_test\n",
    "\n",
    "    drawing_std = y_quantiles is not None\n",
    "    if drawing_std:\n",
    "        ci_low, ci_high = (y_quantiles[:, 0], y_quantiles[:, -1])\n",
    "        drawn_quantile = round(max(quantiles) - min(quantiles), 2)\n",
    "    else:\n",
    "        ci_low, ci_high = y_preds - y_std / 2, y_preds + y_std / 2\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 5))\n",
    "    ax.plot(x_plot_full, y, color=\"black\", linestyle=\"dashed\", label=\"True mean\")\n",
    "    ax.scatter(x_plot_train, y_train, color=\"black\", marker=\"o\", alpha=0.8, label=\"training points\")\n",
    "    ax.plot(x_plot_uq, y_preds, label=f\"mean/median prediction {plot_name}\",  # todo: mean or median?\n",
    "        color=\"green\")\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    label = rf\"{plot_name} {f'{100*drawn_quantile}% CI' if drawing_std else '1 std'}\"\n",
    "    ax.fill_between(x_plot_uq.ravel(), ci_low, ci_high, color=\"green\", alpha=0.2, label=label)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"data\")\n",
    "    ax.set_ylabel(\"target\")\n",
    "    ax.set_title(f\"{plot_name} ({uq_type})\")\n",
    "    if save_plot:\n",
    "        filename = f\"{plot_name}_{uq_type}.png\"\n",
    "        filepath = os.path.join(plots_path, filename)\n",
    "        plt.savefig(filepath)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5c392-80b1-4824-86e4-33c01256bbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD_WHITELIST = [\n",
    "    # \"posthoc_conformal_prediction\", # \"posthoc_laplace\", # \"native_quantile_regression\", \"native_gp\",\n",
    "]\n",
    "QUANTILES = [0.05, 0.25, 0.75, 0.95]  # todo: how to handle 0.5? ==> just use mean if needed\n",
    "\n",
    "PLOT_DATA = False\n",
    "PLOT_RESULTS = True  # todo: fix plotting timing?\n",
    "SAVE_PLOTS = True\n",
    "\n",
    "PLOTS_PATH = \"plots\"\n",
    "\n",
    "BASE_MODEL_PARAMS = {\n",
    "    'skip_training': True, # 'n_jobs': -1, # 'model_params_choices': None,\n",
    "}\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "\n",
    "def print_metrics(uq_metrics: dict[str, dict[str, dict[str, Any]]]):\n",
    "    for uq_type, method_metrics in uq_metrics.items():\n",
    "        print(f'{uq_type} metrics:')\n",
    "        for method, metrics in method_metrics.items():\n",
    "            print(f'\\t{method}:')\n",
    "            for metric, value in metrics.items():\n",
    "                print(f'\\t\\t{metric}: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1d173-fa0d-450f-a51e-65184740ec34",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    uq_comparer = My_UQ_Comparer(method_whitelist=METHOD_WHITELIST)\n",
    "    uq_metrics = uq_comparer.compare_methods(QUANTILES,should_plot_data=PLOT_DATA,should_plot_results=PLOT_RESULTS,should_save_plots=SAVE_PLOTS,plots_path=PLOTS_PATH,base_model_params=BASE_MODEL_PARAMS,output_uq_on_train=True,return_results=False,)\n",
    "    print_metrics(uq_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91587858-32ef-47ea-88f6-2a39e7cb8905",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from helpers import standardize\n",
    "\n",
    "\n",
    "class My_UQ_Comparer(UQ_Comparer):\n",
    "    def __init__(self, storage_path='comparison_storage', to_standardize='X', *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.io_helper = IO_Helper(storage_path)\n",
    "        self.to_standardize = to_standardize.lower()\n",
    "\n",
    "    def get_data(self, _n_points_per_group=800):\n",
    "        X_train, X_test, y_train, y_test, X, y = get_data(_n_points_per_group, return_full_data=True)\n",
    "        if 'x' in self.to_standardize:\n",
    "            X_train, X_test, X = standardize(False, X_train, X_test, X)\n",
    "        if 'y' in self.to_standardize:\n",
    "            y_train, y_test, y = standardize(False, y_train, y_test, y)\n",
    "        return X_train, X_test, y_train, y_test, X, y\n",
    "\n",
    "    # todo: type hints!\n",
    "    def compute_metrics(self, y_pred, y_quantiles, y_std, y_true, quantiles=None):\n",
    "        y_true_np = y_true.to_numpy().squeeze()\n",
    "        # todo: sharpness? calibration? PIT? coverage?\n",
    "        # todo: skill score (but what to use as benchmark)?\n",
    "\n",
    "        metrics = {  # todo: improve\n",
    "            \"rmse\": rmse(y_true_np, y_pred), \"smape\": smape(y_true_np, y_pred) / 100,  # scale down to [0, 1]\n",
    "            \"crps\": (# todo: implement\n",
    "                None  # crps_ensemble(y_pred, y_std, y_true_np) if y_std is not None else None\n",
    "            ), \"neg_log_lik\": (nll_gaussian(y_pred, y_std, y_true_np) if y_std is not None else None\n",
    "            ), \"mean_pinball\": (self._mean_pinball_loss(y_pred, y_quantiles, quantiles)\n",
    "                if y_quantiles is not None\n",
    "                else None\n",
    "            ), }\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean_pinball_loss(y_true, y_quantiles, quantiles):\n",
    "        return np.mean([\n",
    "                mean_pinball_loss(y_true, y_quantiles[:, ind], alpha=quantile)\n",
    "                for ind, quantile in enumerate(quantiles)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def train_base_model(self, X_train, y_train, model_params_choices=None, skip_training=True, n_jobs=-1):\n",
    "        # todo: more flexibility in choosing (multiple) base models\n",
    "        if model_params_choices is None:\n",
    "            model_params_choices = {\n",
    "                \"max_depth\": randint(2, 30), \"n_estimators\": randint(10, 100), }\n",
    "        return train_base_model_cp(RandomForestRegressor, model_params_choices=model_params_choices, X_train=X_train, y_train=y_train, skip_training=skip_training, cv_n_iter=10, n_jobs=n_jobs, io_helper=self.io_helper\n",
    "        )\n",
    "\n",
    "    def train_base_model2(self, X_train: pd.DataFrame, y_train: pd.DataFrame, model_params_choices=None, n_epochs=1000, batch_size=1, random_state=711, verbose=True, skip_training=True, save_trained=True, model_filename=\"_laplace_base.pth\"):\n",
    "        \"\"\"\n",
    "\n",
    "        :param model_filename:\n",
    "        :param save_trained:\n",
    "        :param skip_training:\n",
    "        :param verbose:\n",
    "        :param X_train: shape (n_samples, n_dims)\n",
    "        :param y_train: shape (n_samples, n_dims)\n",
    "        :param model_params_choices:\n",
    "        :param n_epochs:\n",
    "        :param batch_size:\n",
    "        :param random_state:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # todo: more flexibility in choosing (multiple) base models\n",
    "        torch.manual_seed(random_state)\n",
    "\n",
    "        dim_in, dim_out = X_train.shape[-1], y_train.shape[-1]\n",
    "        model = torch.nn.Sequential(torch.nn.Linear(dim_in, 50), torch.nn.Tanh(), torch.nn.Linear(50, dim_out)\n",
    "        ).float()\n",
    "\n",
    "        if skip_training:\n",
    "            print(\"skipping base model training\")\n",
    "            try:\n",
    "                model = self.io_helper.load_torch_model(model_filename, weights_only=False)\n",
    "                model.eval()\n",
    "                return model\n",
    "            except FileNotFoundError:\n",
    "                # todo\n",
    "                print(\"error. model not found, so training cannot be skipped. training from scratch\"\n",
    "                )\n",
    "\n",
    "        # todo: consistent input expectations!\n",
    "        train_loader = self._get_train_loader(X_train, y_train, batch_size)\n",
    "\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "        iterable = tqdm(range(n_epochs)) if verbose else range(n_epochs)\n",
    "        for _ in iterable:\n",
    "            for X, y in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                loss = criterion(model(X), y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        if save_trained:\n",
    "            torch.save(model, model_filename)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def posthoc_conformal_prediction(self, X_train, y_train, X_test, quantiles, model, random_state=42\n",
    "    ):\n",
    "        cv = BlockBootstrap(n_resamplings=10, n_blocks=10, overlapping=False, random_state=random_state\n",
    "        )\n",
    "        alphas = self.pis_from_quantiles(quantiles)\n",
    "        y_pred, y_pis = estimate_pred_interals_no_pfit_enbpi(model, cv, alphas, X_test, X_train, y_train, skip_base_training=True, io_helper=self.io_helper\n",
    "        )\n",
    "        # todo!\n",
    "        y_quantiles = self.quantiles_from_pis(y_pis)\n",
    "        y_std = None  # self.stds_from_quantiles(y_quantiles)\n",
    "        return y_pred, y_quantiles, y_std\n",
    "\n",
    "    def posthoc_laplace(self, X_train: pd.DataFrame, y_train: pd.DataFrame, X_test: pd.DataFrame, quantiles, model, n_epochs=1000, batch_size=1, random_state=711, verbose=True):\n",
    "        # todo: offer option to alternatively optimize parameters and hyperparameters of the prior jointly (cf. example\n",
    "        #  script)?\n",
    "        train_loader = self._get_train_loader(X_train, y_train, batch_size)\n",
    "\n",
    "        la = Laplace(model, \"regression\")\n",
    "        la.fit(train_loader)\n",
    "        log_prior, log_sigma = (torch.ones(1, requires_grad=True), torch.ones(1, requires_grad=True))\n",
    "        hyper_optimizer = torch.optim.Adam([log_prior, log_sigma], lr=1e-1)\n",
    "        iterable = tqdm(range(n_epochs)) if verbose else range(n_epochs)\n",
    "        for _ in iterable:\n",
    "            hyper_optimizer.zero_grad()\n",
    "            neg_marglik = -la.log_marginal_likelihood(log_prior.exp(), log_sigma.exp())\n",
    "            neg_marglik.backward()\n",
    "            hyper_optimizer.step()\n",
    "\n",
    "        # # Serialization for fitted quantities\n",
    "        # state_dict = la.state_dict()\n",
    "        # torch.save(state_dict, \"state_dict.bin\")\n",
    "        #\n",
    "        # la = Laplace(model, \"regression\", subset_of_weights=\"all\", hessian_structure=\"full\")\n",
    "        # # Load serialized, fitted quantities\n",
    "        # la.load_state_dict(torch.load(\"state_dict.bin\"))\n",
    "\n",
    "        X_test = self._df_to_tensor(X_test)\n",
    "        f_mu, f_var = la(X_test)\n",
    "\n",
    "        f_mu = f_mu.squeeze().detach().cpu().numpy()\n",
    "        f_sigma = f_var.squeeze().detach().sqrt().cpu().numpy()\n",
    "        pred_std = np.sqrt(f_sigma**2 + la.sigma_noise.item() ** 2)\n",
    "\n",
    "        y_pred, y_std = f_mu, pred_std\n",
    "        y_quantiles = self.quantiles_gaussian(quantiles, y_pred, y_std)\n",
    "        return y_pred, y_quantiles, y_std\n",
    "\n",
    "    def native_quantile_regression(self, X_train, y_train, X_test, quantiles):\n",
    "        y_pred, y_quantiles = estimate_quantiles_qr(X_train, y_train, X_test, alpha=quantiles\n",
    "        )\n",
    "        y_std = self.stds_from_quantiles(y_quantiles)\n",
    "        return y_pred, y_quantiles, y_std\n",
    "\n",
    "    # noinspection PyMethodMayBeStatic\n",
    "    # todo: make static?\n",
    "    def native_gp(self, X_train, y_train, X_test, quantiles):\n",
    "        kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "        gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=200\n",
    "        )\n",
    "        gaussian_process.fit(X_train, y_train)\n",
    "\n",
    "        mean_prediction, std_prediction = gaussian_process.predict(X_test, return_std=True\n",
    "        )\n",
    "        y_pred, y_std = mean_prediction, std_prediction\n",
    "        y_quantiles = self.quantiles_gaussian(quantiles, y_pred, y_std)\n",
    "        return y_pred, y_quantiles, y_std\n",
    "\n",
    "    @staticmethod\n",
    "    def _df_to_tensor(df: pd.DataFrame, dtype=float) -> torch.Tensor:\n",
    "        return torch.Tensor(df.to_numpy(dtype=dtype))\n",
    "\n",
    "    @classmethod\n",
    "    def _get_train_loader(cls, X_train, y_train, batch_size):\n",
    "        X_train, y_train = map(lambda df: cls._df_to_tensor(df, dtype=float), (X_train, y_train)\n",
    "        )\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "        return train_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def quantiles_gaussian(quantiles, y_pred, y_std):\n",
    "        # todo: does this work for multi-dim outputs?\n",
    "        return np.array([norm.ppf(quantiles, loc=mean, scale=std)\n",
    "                                for mean, std in zip(y_pred, y_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ac465-e46d-4259-9784-6cc8c46960b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = QUANTILES\n",
    "_n_points_per_group = 800\n",
    "\n",
    "uq_comparer = My_UQ_Comparer(to_standardize='Xy')\n",
    "X_train, X_test, y_train, y_test, X, y = uq_comparer.get_data(_n_points_per_group)\n",
    "print([arr.shape for arr in [X_train, X_test, y_train, y_test, X, y]])\n",
    "plot_data(X_train, X_test, y_train, y_test, save_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afcfaa-0585-4a93-93e2-8bcafbc46c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import kernels as kernels\n",
    "import re\n",
    "\n",
    "RBF = kernels.RBF\n",
    "WhiteKernel = kernels.WhiteKernel\n",
    "ConstantKernel = kernels.ConstantKernel\n",
    "\n",
    "\n",
    "def test_kernel(kernel, kernel_name):\n",
    "    gaussian_process = GaussianProcessRegressor(kernel=kernel, random_state=0, normalize_y=False, n_restarts_optimizer=10)\n",
    "    print('fitting...')\n",
    "    gaussian_process = gaussian_process.fit(X_train, y_train)\n",
    "    print('done. result:', gaussian_process.kernel_)\n",
    "    \n",
    "    print('predicting...')\n",
    "    mean_prediction, std_prediction = gaussian_process.predict(X, return_std=True)\n",
    "    \n",
    "    # kernel_name = re.search(\"<class '.+\\.(\\w+)'>\", str(kernel.__class__)).groups()[0]\n",
    "    plot_name = f'gp_{kernel_name}'\n",
    "    my_plot(X_train, X_test, y_train, y, mean_prediction, None, std_prediction, quantiles, output_uq_on_train=True, plot_name=plot_name, save_plot=True,plots_path=os.path.join('.', 'temp_gp_plots'))\n",
    "\n",
    "\n",
    "def my_plot(X_train, X_test, y_train, y, y_preds, y_quantiles, y_std, quantiles, output_uq_on_train, plot_name, save_plot=True, plots_path=\".\"):\n",
    "    num_train_steps, num_test_steps = X_train.shape[0], X_test.shape[0]\n",
    "\n",
    "    x_plot_train = np.arange(num_train_steps)\n",
    "    x_plot_full = np.arange(num_train_steps + num_test_steps)\n",
    "    x_plot_test = x_plot_train + num_test_steps  # shifting\n",
    "    x_plot_uq = x_plot_full if output_uq_on_train else x_plot_test\n",
    "\n",
    "    drawing_std = y_quantiles is not None\n",
    "    if drawing_std:\n",
    "        ci_low, ci_high = (y_quantiles[:, 0], y_quantiles[:, -1])\n",
    "        drawn_quantile = round(max(quantiles) - min(quantiles), 2)\n",
    "    else:\n",
    "        ci_low, ci_high = y_preds - y_std / 2, y_preds + y_std / 2\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(13, 5))\n",
    "    ax.plot(x_plot_full, y, color=\"black\", linestyle=\"dashed\", label=\"True mean\")\n",
    "    ax.scatter(x_plot_train, y_train, color=\"black\", marker=\"o\", alpha=0.8, label=\"training points\")\n",
    "    ax.plot(x_plot_uq, y_preds, label=\"mean/median prediction\", color=\"green\")\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    label = rf'{100*drawn_quantile}% CI' if drawing_std else '1 std'\n",
    "    ax.fill_between(x_plot_uq.ravel(), ci_low, ci_high, color=\"green\", alpha=0.2, label=label)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"data\")\n",
    "    ax.set_ylabel(\"target\")\n",
    "    ax.set_title(f\"{plot_name}\")\n",
    "    if save_plot:\n",
    "        filename = f\"{plot_name}.png\"\n",
    "        filepath = os.path.join(plots_path, filename)\n",
    "        plt.savefig(filepath)\n",
    "    plt.show()\n",
    "\n",
    "kernels = {\n",
    "    'RBF': RBF(),\n",
    "    # 'Noise': WhiteKernel(),\n",
    "    # 'const': ConstantKernel(),\n",
    "    'RBF and noise': RBF() + WhiteKernel(),\n",
    "    # 'c times RBF and noise': ConstantKernel() * RBF() + WhiteKernel(),\n",
    "    # 'RBF and c times noise': RBF() + ConstantKernel() * WhiteKernel(),\n",
    "    # 'c times RBF and c times noise': ConstantKernel() * RBF() + ConstantKernel() * WhiteKernel(),\n",
    "    # 'c and RBF and noise': ConstantKernel() + RBF() + WhiteKernel(),\n",
    "    # 'c and c times RBF and noise': ConstantKernel() + ConstantKernel() * RBF() + WhiteKernel(),\n",
    "    # 'c and RBF and c times noise': ConstantKernel() + RBF() + ConstantKernel() * WhiteKernel(),\n",
    "    # 'c and c times RBF and c times noise': ConstantKernel() + ConstantKernel() * RBF() + ConstantKernel() * WhiteKernel(),\n",
    "    # kernels.ConstantKernel(1) + kernels.ConstantKernel(1) * kernels.RBF() + kernels.WhiteKernel()\n",
    "}\n",
    "for i, (kernel_name, kernel) in enumerate(kernels.items(), start=1):\n",
    "    print(f'testing kernel {i}/{len(kernels)}:', kernel_name)\n",
    "    test_kernel(kernel, kernel_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
